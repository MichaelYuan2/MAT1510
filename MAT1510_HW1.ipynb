{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MichaelYuan2/MAT1510/blob/main/MAT1510_HW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJXPSClGRHxn",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Import Packages\n",
        "# Do not touch. You will not need to import any other packages outside of these!\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title MNIST Dataset\n",
        "# Do not touch. You do not need to use this\n",
        "transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.1307,), (0.3081,))\n",
        "            ])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "  datasets.MNIST('./', download=True, train=True, transform=transform),\n",
        "  batch_size=128, shuffle=True, drop_last=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "  datasets.MNIST('./', download=True, train=False, transform=transform),\n",
        "  batch_size=1024, shuffle=False, drop_last=False)"
      ],
      "metadata": {
        "id": "mz9OeUyoRP5b",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Parameter intialization\n",
        "# Do not touch. You do not need to use this function\n",
        "def initializeParam(weight, bias):\n",
        "    stdv = 1. / math.sqrt(weight.size(1))\n",
        "    weight.data.uniform_(-stdv, stdv)\n",
        "    bias.data.uniform_(-stdv, stdv)"
      ],
      "metadata": {
        "id": "TGeLebylNsPV",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "lr = 0.1\n",
        "W1 = torch.empty(64, 28*28)\n",
        "W2 = torch.empty(32, 64)\n",
        "W3 = torch.empty(10, 32)\n",
        "\n",
        "b1 = torch.empty(64)\n",
        "b2 = torch.empty(32)\n",
        "b3 = torch.empty(10)\n",
        "\n",
        "\n",
        "# initialize parameters\n",
        "initializeParam(W1, b1)\n",
        "initializeParam(W2, b2)\n",
        "initializeParam(W3, b3)\n",
        "\n",
        "# !!!! RELU FUNCTION DEFINED HERE !!!!\n",
        "sigma = torch.nn.ReLU()\n",
        "\n",
        "\n",
        "losses = []\n",
        "trainAcc = []\n",
        "for epoch in range(3):\n",
        "    for x, y in train_loader:\n",
        "        # Forward Pass\n",
        "        # HINT: @ can be used for matrix multiplication. sigma defined above\n",
        "        # can be used for ReLU\n",
        "        B = x.shape[0] # This is the batch size\n",
        "        x = x.view(-1, 28*28)\n",
        "        z1 =\n",
        "        h1 =\n",
        "        z2 =\n",
        "        h2 =\n",
        "        z3 =\n",
        "        loss = criterion(z3, y)\n",
        "\n",
        "        # Calculate backprop errors\n",
        "        # HINT: You can obtain the mask of the positive entries of a tensor, T, by\n",
        "        # writing (T > 0).  * can be used for element wise matrix multiplication.\n",
        "        oneHotTargets = F.one_hot(y)\n",
        "        probabilities = F.softmax(z3, dim=1)\n",
        "\n",
        "        #HINT: Don't forget to normalize by the batch size!\n",
        "        delta_3 =\n",
        "        delta_2 =\n",
        "        delta_1 =\n",
        "\n",
        "        # Calculate gradients\n",
        "        grad_W3 =\n",
        "        grad_W2 =\n",
        "        grad_W1 =\n",
        "\n",
        "        #HINT: torch.sum() might be useful here\n",
        "        grad_b3 =\n",
        "        grad_b2 =\n",
        "        grad_b1 =\n",
        "\n",
        "        # Update parameters\n",
        "        # HINT: +, -, * can be used for matrix addition, subtraction, and scalar\n",
        "        # multiplication respectively\n",
        "        W3 =\n",
        "        W2 =\n",
        "        W1 =\n",
        "        b3 =\n",
        "        b2 =\n",
        "        b1 =\n",
        "        losses.append(loss)\n",
        "\n",
        "        # compute train accuracy -- do not touch\n",
        "        _, predictions = probabilities.max(1)\n",
        "        num_correct = (predictions == y).sum()\n",
        "        num_samples = predictions.size(0)\n",
        "        trainAcc.append(num_correct/num_samples)\n",
        "\n",
        "# Plot loss and train accuracy\n",
        "plt.plot(losses)\n",
        "plt.title(\"Loss\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(trainAcc)\n",
        "plt.title(\"Mini Batch Train Acccuracy\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uYac-ijBRUnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yLg97qE2Vk60"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}